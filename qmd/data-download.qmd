---
execute:
  eval: false
---

# LogoClim: WorldClim 2.1 Data Download

## Overview

This document provides a step-by-step guide to download the WorldClim 2.1 data from the [WorldClim website](https://worldclim.org/data/monthlywth.html).

::: {.callout-note}
Due to UC Davis server constraints, it's much faster to download WorldClim 2.1 raw data from the `LogoClim` backups stored on the Open Science Framework (OSF). Click [here](https://osf.io/2bpjh/) to access this data.
:::

::: {.callout-important}
This process may take some time to complete. Please be patient.
:::

## Setting the Environment

```{r}
#| eval: false

library(beepr)
library(cli)
library(dplyr)
library(fs)
library(groomr) # github.com/danielvartan/groomr
library(here)
library(magrittr)
library(orbis) # github.com/danielvartan/orbis
library(purrr)
library(rutils) # github.com/danielvartan/rutils
library(rvest)
library(stringr)
```

## Setting the Initial Variables

### Options

```{r}
options(cli.progress_show_after = 0)
```

### Series

Pick **one** of the following.

```{r}
series <- "historical-climate-data"
```

```{r}
#| eval: false

series <- "historical-monthly-weather-data"
```

```{r}
#| eval: false

series <- "future-climate-data"
```

### Resolution

Pick **one** of the following.

```{r}
resolution <- "10m"
```

```{r}
#| eval: false

resolution <- "5m"
```

```{r}
#| eval: false

resolution <- "2.5m"
```

```{r}
#| eval: false

resolution <- "30s"
```

```{r}
#| eval: false

resolution <- "all"
```

### Global Climate Model

::: {.callout-note}
This is only useful when dealing with future climate data. Here you can specify the model(s) you want to download. If you want to download all models, set `model <- NULL`.

Run `model <- NULL` when downloading other series.
:::

Pick **one** of the following.

```{r}
model <- NULL
```

```{r}
#| eval: false

model <- "ACCESS-CM2"
```

```{r}
#| eval: false

model <- c(
  "ACCESS-CM2", "BCC-CSM2-MR", "CMCC-ESM2", "EC-Earth3-Veg", "FIO-ESM-2-0",
  "GFDL-ESM4", "GISS-E2-1-G", "HadGEM3-GC31-LL", "INM-CM5-0", "IPSL-CM6A-LR",
  "MIROC6", "MPI-ESM1-2-HR", "MRI-ESM2-0", "UKESM1-0-LL"
)
```

### Directories

Check the paths to the directories where the data will be stored.

```{r}
raw_data_dir <- here::here("data-raw")
```

```{r}
wc_raw_data_dir <- fs::path(raw_data_dir, "worldclim")
```

```{r}
wc_raw_data_series_dir <- fs::path(wc_raw_data_dir, series)
```

```{r}
wc_raw_data_series_res_dir <- fs::path(wc_raw_data_dir, series, resolution)
```

```{r}
dirs <- c(
  raw_data_dir, wc_raw_data_dir, wc_raw_data_series_dir,
  wc_raw_data_series_res_dir
)

for (i in dirs) {
  if (!dir.exists(i)) {
    fs::dir_create(i, recurse = TRUE)
  }
}
```

## Scrapping the Source

```{r}
html <-
  orbis::get_wc_url(series, resolution) |>
  rvest::read_html()
```

```{r}
urls <-
  html |>
  rvest::html_elements("a") |>
  rvest::html_attr("href") |>
  stringr::str_subset("geodata")
```

```{r}
if (!resolution == "all") {
  urls <-
    urls %>%
    magrittr::extract(
      stringr::str_detect(
        basename(.),
        paste0("(?<=_)", resolution)
      )
    )
}
```

```{r}
if (!is.null(model)) {
  urls <-
    urls %>%
    magrittr::extract(
      stringr::str_detect(
        basename(.),
        paste0("(?<=_)", model)
      )
    )
}
```

## Creating the Metadata

```{r}
sizes <-
  urls |>
  purrr::map_dbl(
    .f = rutils::get_file_size,
    .progress = TRUE
  ) |>
  fs::as_fs_bytes()

beepr::beep(1)
```

```{r}
metadata <-
  dplyr::tibble(
    url = urls,
    file = basename(urls),
    size = sizes
  ) |>
  dplyr::arrange(size) |>
  dplyr::mutate(
  size_cum_sum =
      size |>
      tidyr::replace_na() |>
      cumsum() |>
      fs::as_fs_bytes()
  )
```

```{r}
metadata
```

## Checking for Errors

```{r}
{
  cli::cli_alert_info(
    paste0(
      "{.strong {cli::col_red(rutils:::count_na(metadata$size))}} ",
      "url requests resulted in error."
    )
  )

  if (rutils::count_na(metadata$size) > 0) {
    cli::cli_alert_info("Their file names are:")
    cli::cli_li(metadata$file[is.na(metadata$size)])
  }
}
```

## Downloading the Files

```{r}
if (series == "future-climate-data") {
  dir <- fs::path(wc_raw_data_series_res_dir, "tif")
} else {
  dir <- fs::path(wc_raw_data_series_res_dir, "zip")
}

if (!dir.exists(dir)) {
  dir |> fs::dir_create(recurse = TRUE)
}
```

```{r}
broken_links <-
  metadata |>
  dplyr::pull(url) |>
  rutils::download_file(dir = dir, broken_links = TRUE)

beepr::beep(1)
```

If the download process was interrupted or not all files were downloaded, run the code chunk below to retry downloading only the missing files.

```{r}
#| eval: false

files <- dir |> fs::dir_ls(type = "file")

broken_links <-
  metadata |>
  dplyr::filter(!file %in% basename(files)) |>
  dplyr::pull(url) |>
  rutils::download_file(dir = dir, broken_links = TRUE)

beepr::beep(1)
```

## Zipping the Files (Optional)

This is only useful when dealing with future climate data.

```{r}
zip_dir <- fs::path(wc_raw_data_series_res_dir, "zip")

if (!dir.exists(zip_dir)) {
  zip_dir |> fs::dir_create(recurse = TRUE)
}
```

```{r}
#| eval: false
#| output: false

metadata |>
  dplyr::pull(file) |>
  groomr::zip_files_by_pattern(
    pattern = model,
    suffix = paste0("_", resolution),
    max_size = fs::fs_bytes("5GB"),
    root = dir,
    dir = zip_dir
  )

beepr::beep(1)
```
